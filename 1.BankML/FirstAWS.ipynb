{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ecf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "#used to read s3 buckets if they are public from our local machine\n",
    "# Use the AWS SDK for Python (Boto3) to create, configure, and manage AWS services,\n",
    "# such as Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Simple Storage Service (Amazon S3).\n",
    "# The SDK provides an object-oriented API as well as low-level access to AWS services.\n",
    "\n",
    "import boto3\n",
    "# To utilize inbuilt algorithms\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri  \n",
    "\n",
    "#need to create sessions\n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb71e2",
   "metadata": {},
   "source": [
    "## Create a S3 bucket to store the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc3c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'benuramlbucket1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88851a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before create an s3 bucket first need to create a session\n",
    "my_region = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5c474be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "# check  the region\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42903d0",
   "metadata": {},
   "source": [
    "Get access of the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c9020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05160d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "# if only the region is us-east-1, s3 bucket should create on s3 console\n",
    "try:\n",
    "    if my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    print('s3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('s3 errror' , e) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492097b",
   "metadata": {},
   "source": [
    "ML Model output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "301638b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://benuramlbucket1/mlmodel_first_aws/output\n"
     ]
    }
   ],
   "source": [
    "prefix = \"mlmodel_first_aws\"\n",
    "output_path =\"s3://{}/{}/output\".format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53e21a",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11f986a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Downloaded bank_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "try:\n",
    "    urllib.request.urlretrieve('https://raw.githubusercontent.com/Benura2020/AWS-Playground/main/1.BankML/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv', 'bank_clean.csv')\n",
    "    print('Success: Downloaded bank_clean.csv')\n",
    "except Exception as e:\n",
    "    print('Data load error: ', e)\n",
    "    \n",
    "# this dataset download into sagemaker notebook storage (not to S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ae00d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Data loaded intothe DataFrame\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv', index_col=0)\n",
    "    print('Success: Data loaded intothe DataFrame')\n",
    "except Exception as e:\n",
    "    print('Data load error: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9a145a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>no_previous_contact</th>\n",
       "      <th>not_working</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>y_no</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  campaign  pdays  previous  no_previous_contact  not_working  \\\n",
       "0   56         1    999         0                    1            0   \n",
       "1   57         1    999         0                    1            0   \n",
       "2   37         1    999         0                    1            0   \n",
       "3   40         1    999         0                    1            0   \n",
       "4   56         1    999         0                    1            0   \n",
       "\n",
       "   job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  ...  \\\n",
       "0           0                0                 0              1  ...   \n",
       "1           0                0                 0              0  ...   \n",
       "2           0                0                 0              0  ...   \n",
       "3           1                0                 0              0  ...   \n",
       "4           0                0                 0              0  ...   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                1                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                1                0                0   \n",
       "\n",
       "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \\\n",
       "0                0                 0                     1                 0   \n",
       "1                0                 0                     1                 0   \n",
       "2                0                 0                     1                 0   \n",
       "3                0                 0                     1                 0   \n",
       "4                0                 0                     1                 0   \n",
       "\n",
       "   y_no  y_yes  \n",
       "0     1      0  \n",
       "1     1      0  \n",
       "2     1      0  \n",
       "3     1      0  \n",
       "4     1      0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62c6ce",
   "metadata": {},
   "source": [
    "Dataset - a bank dataset. after promoting the age group, if they buy or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceb03531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#train and test split\n",
    "\n",
    "import numpy as np\n",
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fd6d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when working with aws sagemaker the dependent feature should be first column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d7ba92",
   "metadata": {},
   "source": [
    "## Saving Train And Test Into Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6429218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "import os\n",
    "\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'],\n",
    "                                                axis=1)],\n",
    "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "914a5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1) ], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session( ) . resource('s3' ) . Bucket(bucket_name).Object(os.path. join(prefix, 'test/test.csv') ) . upload_file('test.csv')\n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c7640",
   "metadata": {},
   "source": [
    "## Get the container of get_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1920ccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Building models with xgboost algorithm\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name,\n",
    "                            'xgboost',\n",
    "                            repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b2af3",
   "metadata": {},
   "source": [
    "## Initialize Hyperparameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ed7c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "\t\"max_depth\":\"5\",\n",
    "\t\"eta\":\"0.2\",\n",
    "\t\"gamma\":\"4\",\n",
    "\t\"min_child_weight\":\"6\",\n",
    "\t\"subsample\":\"0.7\",\n",
    "\t\"objective\":\"binary:logistic\",\n",
    "\t\"num_round\":50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ab015f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_use_spot_instances has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_wait has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "#construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container,\n",
    "                                        hyperparameters=hyperparameters,\n",
    "                                        role=sagemaker.get_execution_role(),\n",
    "                                        train_instance_count=1,\n",
    "                                        train_instance_type='ml.m5.2xlarge',\n",
    "                                        train_volume_size=5, # 5 GB\n",
    "                                        output_path=output_path,\n",
    "                                        train_use_spot_instances=True,\n",
    "                                        train_max_run=300,\n",
    "                                        train_max_wait=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9658933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-03-29-03-30-13-106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-29 03:30:13 Starting - Starting the training job...\n",
      "2024-03-29 03:30:28 Starting - Preparing the instances for training...\n",
      "2024-03-29 03:31:03 Downloading - Downloading input data...\n",
      "2024-03-29 03:31:18 Downloading - Downloading the training image...\n",
      "2024-03-29 03:32:09 Training - Training image download completed. Training in progress.\n",
      "2024-03-29 03:32:09 Uploading - Uploading generated training model.\u001b[34m[2024-03-29 03:32:05.176 ip-10-0-152-96.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34m[03:32:05] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[03:32:05] 12357x59 matrix with 729063 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2024-03-29 03:32:05.341 ip-10-0-152-96.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-03-29 03:32:05.342 ip-10-0-152-96.ec2.internal:7 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-03-29 03:32:05.342 ip-10-0-152-96.ec2.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-03-29 03:32:05.342 ip-10-0-152-96.ec2.internal:7 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-03-29 03:32:05.342 ip-10-0-152-96.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 28831 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 12357 rows\u001b[0m\n",
      "\u001b[34m[03:32:05] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.10079#011validation-error:0.10528\u001b[0m\n",
      "\u001b[34m[2024-03-29 03:32:05.387 ip-10-0-152-96.ec2.internal:7 INFO hook.py:423] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-03-29 03:32:05.392 ip-10-0-152-96.ec2.internal:7 INFO hook.py:486] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.09968#011validation-error:0.10456\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.10017#011validation-error:0.10375\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.09989#011validation-error:0.10310\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.09996#011validation-error:0.10286\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.09906#011validation-error:0.10261\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.09930#011validation-error:0.10286\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.09951#011validation-error:0.10261\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.09920#011validation-error:0.10286\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.09871#011validation-error:0.10294\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.09868#011validation-error:0.10294\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.09868#011validation-error:0.10326\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.09854#011validation-error:0.10358\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.09892#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.09850#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.09844#011validation-error:0.10326\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.09857#011validation-error:0.10318\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.09799#011validation-error:0.10318\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.09816#011validation-error:0.10383\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.09857#011validation-error:0.10383\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.09830#011validation-error:0.10350\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.09826#011validation-error:0.10318\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.09847#011validation-error:0.10399\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.09833#011validation-error:0.10407\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.09812#011validation-error:0.10415\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09812#011validation-error:0.10399\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.09774#011validation-error:0.10375\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.09781#011validation-error:0.10375\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.09781#011validation-error:0.10391\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.09778#011validation-error:0.10367\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.09781#011validation-error:0.10383\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.09771#011validation-error:0.10358\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.09743#011validation-error:0.10391\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.09753#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.09767#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09757#011validation-error:0.10350\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.09757#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.09736#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.09750#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.09733#011validation-error:0.10350\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09705#011validation-error:0.10358\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.09701#011validation-error:0.10383\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.09712#011validation-error:0.10407\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.09698#011validation-error:0.10375\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.09733#011validation-error:0.10342\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.09736#011validation-error:0.10367\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.09746#011validation-error:0.10350\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.09736#011validation-error:0.10358\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.09712#011validation-error:0.10334\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.09712#011validation-error:0.10318\u001b[0m\n",
      "\n",
      "2024-03-29 03:32:25 Completed - Training job completed\n",
      "Training seconds: 82\n",
      "Billable seconds: 37\n",
      "Managed Spot Training savings: 54.9%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train, 'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae69d7e9",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39094547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-03-29-03-37-09-400\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-03-29-03-37-09-400\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-03-29-03-37-09-400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "# endpoint\n",
    "my_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3cfb9d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer #input in the form of tabloid it needs to be converted into serial\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "# my_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "my_predictor.serializer = CSVSerializer() # set the serializer type\n",
    "predictions = my_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c192a15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05214286, 0.05660191, 0.05096195, ..., 0.03436061, 0.02942475,\n",
       "       0.03715819])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddaed9",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b09751fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate:89.7%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    91% (10785)    34% (151)\n",
      "Purchase        9% (1124)     66% (297) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from documentation\n",
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed' ], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0, 1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate:\", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:.0f}% ({2}){3:>6.0f}% ({4})\".format(\"No Purchase\", tn / (tn + fn) * 100, tn, fp / (tp + fp) * 100, fp))\n",
    "print(\"{0:<16}{1:.0f}% ({2}){3:>7.0f}% ({4}) \\n\".format(\"Purchase\", fn / (tn + fn) * 100, fn, tp / (tp + fp) * 100, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3d31965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-xgboost-2024-03-29-03-37-09-400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'MB3SJ4609BGMDWFN',\n",
       "   'HostId': 'YP29GH6/jlx+cpsIDhylVuT78+f6M/ppaY0Wht4DKtzHxYR83yU+LVdYcG7L5dQgrTwMMCKcoyc=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'YP29GH6/jlx+cpsIDhylVuT78+f6M/ppaY0Wht4DKtzHxYR83yU+LVdYcG7L5dQgrTwMMCKcoyc=',\n",
       "    'x-amz-request-id': 'MB3SJ4609BGMDWFN',\n",
       "    'date': 'Fri, 29 Mar 2024 04:08:51 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/index/000000000/000000000020_worker_0.json'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/output/model.tar.gz'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'mlmodel_first_aws/train/train.csv'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/profiler-output/system/incremental/2024032903/1711683060.algo-1.json'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/events/000000000030/000000000030_worker_0.tfevents'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/profiler-output/system/incremental/2024032903/1711683120.algo-1.json'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/claim.smd'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'mlmodel_first_aws/test/test.csv'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/index/000000000/000000000010_worker_0.json'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/events/000000000040/000000000040_worker_0.tfevents'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/index/000000000/000000000030_worker_0.json'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/index/000000000/000000000040_worker_0.json'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/events/000000000010/000000000010_worker_0.tfevents'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/events/000000000020/000000000020_worker_0.tfevents'},\n",
       "   {'Key': 'mlmodel_first_aws/output/sagemaker-xgboost-2024-03-29-03-30-13-106/debug-output/collections/000000000/worker_0_collections.json'}]}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete endpoint\n",
    "sagemaker.Session().delete_endpoint(my_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117774c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
